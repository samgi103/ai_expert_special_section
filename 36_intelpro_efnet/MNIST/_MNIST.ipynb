{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mz4IYCpSSI4-"
   },
   "source": [
    "# MNIST handwritten digits classification\n",
    "\n",
    "In this notebook, we'll train a multi-layer perceptron model to classify MNIST digits using **PyTorch**. \n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "j2_cre7tSI4_",
    "outputId": "67f0f3f1-fc4a-4b91-b337-ae012876d992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.5.1+cu101 CUDA: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print('Using PyTorch version:', torch.__version__, 'CUDA:', cuda)\n",
    "\n",
    "#torch.manual_seed(42)\n",
    "#if cuda:\n",
    "#    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lDqpyifSI5F"
   },
   "source": [
    "## Data\n",
    "\n",
    "Next we'll load the MNIST data.  First time we may have to download the data, which can take a while.\n",
    "\n",
    "Note that we are here using the MNIST test data for *validation*, instead of for testing the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iLgqFI6SI5F"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kx-ZwE5_SI5J"
   },
   "source": [
    "The train and test data are provided via data loaders that provide iterators over the datasets. The first element of training data (`X_train`) is a 4th-order tensor of size (`batch_size`, 1, 28, 28), i.e. it consists of a batch of images of size 1x28x28 pixels. `y_train` is a vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "iLPWAVvKSI5L",
    "outputId": "64fc1cdb-0175-43a3-b9df-1ad881a03402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SpDy6WnpSI5R"
   },
   "source": [
    "Here are the first 10 training digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "colab_type": "code",
    "id": "8MlxmObrSI5S",
    "outputId": "79cff6cd-9592-4197-976a-b9937c492228"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray\")\n",
    "    plt.title('Class: '+str(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CG_qdfGySI5W"
   },
   "source": [
    "## MLP network definition\n",
    "\n",
    "Let's define the network as a Python class.  We have to write the `__init__()` and `forward()` methods, and PyTorch will automatically generate a `backward()` method for computing the gradients for the backward pass.\n",
    "\n",
    "Finally, we define an optimizer to update the model parameters based on the computed gradients.  We select *stochastic gradient descent (with momentum)* as the optimization algorithm, and set *learning rate* to 0.01.  Note that there are [several different options](http://pytorch.org/docs/optim.html#algorithms) for the optimizer in PyTorch that we could use instead of *SGD*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lrBHEGe3SI5X"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 50)\n",
    "        self.fc1_drop = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc2_drop = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_drop(x)\n",
    "        return F.log_softmax(self.fc3(x))\n",
    "\n",
    "model = Net()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvPiIEerSI5d"
   },
   "source": [
    "## Learning with Multi-layer perceptron\n",
    "\n",
    "Let's now define functions to `train()` and `test()` the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8FQo3qOSI5e"
   },
   "outputs": [],
   "source": [
    "def train(epoch, log_interval=100):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYlOQPWtSI5j"
   },
   "outputs": [],
   "source": [
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        val_loss += F.nll_loss(output, target).item()\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2-KllSwSI5m"
   },
   "source": [
    "Now we are ready to train our model using the `train()` function.  An *epoch* means one pass through the whole training data. After each epoch, we evaluate the model using `test()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYv1XeYYSI5n"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2xveJPKSI5q"
   },
   "source": [
    "Let's now visualize how the training progressed. \n",
    "\n",
    "* *Loss* is a function of the difference of the network output and the target values.  We are minimizing the loss function during training so it should decrease over time.\n",
    "* *Accuracy* is the classification accuracy for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IEzKVf2BSI5r"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), lossv)\n",
    "plt.title('validation loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), accv)\n",
    "plt.title('validation accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-kJ0pgXcUI91"
   },
   "source": [
    "##  Lab 1-1 / Learing with simple CNN \n",
    "### Make a model in ppt slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85ZahjonYcRN"
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"ConvNet -> Max_Pool -> RELU -> ConvNet -> Max_Pool -> RELU -> FC -> RELU -> FC -> SOFTMAX\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = NotImplemented\n",
    "        self.maxpool1 = NotImplemented\n",
    "        self.conv2 = NotImplemented\n",
    "        self.maxpool2 = NotImplemented\n",
    "        self.conv3 = NotImplemented\n",
    "        self.fc1 = NotImplemented\n",
    "        self.fc2 = NotImplemented\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 3*3*20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y68NsghrUReN"
   },
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "popLVTp-W-xU"
   },
   "outputs": [],
   "source": [
    "def train_CNN(epoch, log_interval=100):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwNbFToJYzCi"
   },
   "outputs": [],
   "source": [
    "def validate_CNN(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        val_loss += F.nll_loss(output, target).item()\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1yGDW_iLVexl"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_CNN(epoch)\n",
    "    validate_CNN(lossv, accv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byDkJgy_oIeM"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), lossv)\n",
    "plt.title('validation loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), accv)\n",
    "plt.title('validation accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vSmpiYAoOuH"
   },
   "source": [
    "##  Lab1-2 / Learing with VGG like CNN \n",
    "### Let`s make the VGG-like CNN model provided in the ppt slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMWJRNj4ocEv"
   },
   "outputs": [],
   "source": [
    "class SimpleVGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleVGG, self).__init__()\n",
    "        # Your implementation here\n",
    "        self.conv1 = NotImplemented\n",
    "        self.conv2 = NotImplemented\n",
    "        self.conv3 = NotImplemented\n",
    "        self.conv4 = NotImplemented\n",
    "        self.conv5 = NotImplemented\n",
    "        self.conv6 = NotImplemented\n",
    "        self.conv7 = NotImplemented\n",
    "        self.conv8 = NotImplemented\n",
    "        self.Linear1 = NotImplemented\n",
    "        self.drop = NotImplemented\n",
    "        self.Linear2 = NotImplemented\n",
    "        self.last_linear = NotImplemented\n",
    "        # end of your implementation\n",
    "        self.act = nn.ReLU()\n",
    "        self.maxpool2d = nn.MaxPool2d(2, 2)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.act(self.conv4(self.conv3(x)))\n",
    "        x = self.maxpool2d(x) \n",
    "        x = self.act(self.conv6(self.conv5(x)))        \n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.act(self.conv8(self.conv7(x)))\n",
    "        x = self.maxpool2d(x)\n",
    "        x = x.view(-1, 512)\n",
    "        # Your implementation here\n",
    "        return  F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSIdyXfopAnj"
   },
   "outputs": [],
   "source": [
    "model = SimpleVGG()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYbGkeSApN5W"
   },
   "outputs": [],
   "source": [
    "def train_VGG(epoch, log_interval=100):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-zK7xgkpRfM"
   },
   "outputs": [],
   "source": [
    "def validate_VGG(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        val_loss += F.nll_loss(output, target).item()\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6fHGmdkpUWO"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_VGG(epoch)\n",
    "    validate_VGG(lossv, accv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Lab1-3 / Learing with ResNet like CNN \n",
    "### Let`s make the ResNet-like CNN model provided in the ppt slide"
   ]
  },
  {
   "source": [
    "### Residual Block 정의하기 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class residual_block(nn.Module):\n",
    "    def __init(self):\n",
    "        super(ResBlock, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return output\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### SimpleResNet model 만들기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        # Your implementation here\n",
    "       \n",
    "    def forward(self, x):\n",
    "        # Your implementation here\n",
    "        return  F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleResNet()\n",
    "if cuda:\n",
    "    model.cuda()    \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ResNet(epoch, log_interval=100):\r\n",
    "    model.train()\r\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\r\n",
    "        if cuda:\r\n",
    "            data, target = data.cuda(), target.cuda()\r\n",
    "        data, target = Variable(data), Variable(target)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        output = model(data)\r\n",
    "        loss = F.nll_loss(output, target)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        if batch_idx % log_interval == 0:\r\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\r\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ResNet(loss_vector, accuracy_vector):\r\n",
    "    model.eval()\r\n",
    "    val_loss, correct = 0, 0\r\n",
    "    for data, target in validation_loader:\r\n",
    "        if cuda:\r\n",
    "            data, target = data.cuda(), target.cuda()\r\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\r\n",
    "        output = model(data)\r\n",
    "        val_loss += F.nll_loss(output, target).item()\r\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\r\n",
    "        correct += pred.eq(target.data).cpu().sum()\r\n",
    "\r\n",
    "    val_loss /= len(validation_loader)\r\n",
    "    loss_vector.append(val_loss)\r\n",
    "\r\n",
    "    accuracy = 100. * correct / len(validation_loader.dataset)\r\n",
    "    accuracy_vector.append(accuracy)\r\n",
    "    \r\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\r\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_ResNet(epoch)\n",
    "    validate_ResNet(lossv, accv)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "_MNIST.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}