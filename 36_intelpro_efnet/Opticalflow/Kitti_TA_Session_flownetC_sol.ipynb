{"cells":[{"cell_type":"markdown","metadata":{"id":"R7quztHhLtf4"},"source":["#**Optical Flow Estimation**"]},{"cell_type":"markdown","metadata":{"id":"hf57Qhnm5xUI"},"source":["#**Mount Drive**\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20261,"status":"ok","timestamp":1637022530619,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"idigl0KNvSzy","outputId":"bc7883d5-5375-49d6-eb56-1ee1c6707111"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/TA_session')"]},{"cell_type":"markdown","metadata":{"id":"uxwjXnBi5_5P"},"source":["# **Import necessary libraries**"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":26338,"status":"ok","timestamp":1637023069508,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"vWxWJza5MVM8"},"outputs":[],"source":["import torch\n","import torch.backends.cudnn as cudnn\n","import torch.nn.functional as F\n","import glob\n","from tqdm import tqdm\n","from torch.nn.init import kaiming_normal_, constant_\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from imageio import imread, imwrite\n","import numpy as np\n","from torch.utils.data import Dataset\n","import matplotlib.pyplot as plt\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"G0kDEXTy6F1o"},"source":["# **Use KITTI Dataset**"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1637023069511,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"Zw4lBflrnqn1"},"outputs":[],"source":["class Kitti_flow_dataset(Dataset):\n","    def __init__(self, root):\n","        self.root = root\n","        flow_prefix = 'flow_occ'\n","        left_image_prefix = 'image_2'\n","        self.flow_dir = os.path.join(root, flow_prefix)\n","        self.image_dir = os.path.join(root, left_image_prefix)\n","        self.flow_list = sorted(os.listdir(self.flow_dir))\n","        self.image1_list = [flow_file.replace('flow_occ', left_image_prefix) for flow_file in self.flow_list]\n","        self.image2_list = [image1_file.replace('_10', '_11') for image1_file in self.image1_list]\n","    \n","    def __getitem__(self, index):\n","        image1 = imread(os.path.join(self.image_dir, self.image1_list[index]))\n","        image2 = imread(os.path.join(self.image_dir, self.image2_list[index]))\n","        flow = imread(os.path.join(self.flow_dir, self.flow_list[index]))\n","        return image1, image2, flow\n","\n","    def __len__(self):\n","        return len(self.path_list)"]},{"cell_type":"markdown","metadata":{"id":"1USoLTWF6OAy"},"source":["# **Show some example of KITTI dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"executionInfo":{"elapsed":4482,"status":"ok","timestamp":1637023683824,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"0bSyELKa0ybm","outputId":"cdf785c6-ee2d-4fb4-9243-bb42ffbd4d13"},"outputs":[],"source":["base_path = '/content/drive/MyDrive/TA_session'\n","kitti_prefix = 'KITTI2015'\n","kitti_flow_datapath = os.path.join(base_path, kitti_prefix)\n","kitti_dataset = Kitti_flow_dataset(kitti_flow_datapath)\n","\n","image1, image2, flow = kitti_dataset.__getitem__(0)\n","\n","plt.figure()\n","plt.title('kitti image at t0')\n","plt.imshow(image1)\n","plt.show()\n","\n","plt.figure()\n","plt.title('kitti image at t1')\n","plt.imshow(image2)\n","plt.show()\n","\n","plt.figure()\n","plt.title('optical flow ground truth')\n","plt.imshow(flow)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Ec4Cwtwa6WwY"},"source":["# **Data Transform**"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1637023683825,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"kcQzrnfgMYcu"},"outputs":[],"source":["class ArrayToTensor(object):\n","    \"\"\"Converts a numpy.ndarray (H x W x C) to a torch.FloatTensor of shape (C x H x W).\"\"\"\n","\n","    def __call__(self, array):\n","        assert(isinstance(array, np.ndarray))\n","        array = np.transpose(array, (2, 0, 1))\n","        # handle numpy array\n","        tensor = torch.from_numpy(array)\n","        # put it from HWC to CHW format\n","        return tensor.float()"]},{"cell_type":"markdown","metadata":{"id":"itMpu-cm6a1s"},"source":["# **Submodules for convolution neural network**"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1637023683826,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"TmTUSzslM40F"},"outputs":[],"source":["def conv(batchNorm, in_planes, out_planes, kernel_size=3, stride=1):\n","    if batchNorm:\n","        return nn.Sequential(\n","            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, bias=False),\n","            nn.BatchNorm2d(out_planes),\n","            nn.LeakyReLU(0.1,inplace=True)\n","        )\n","    else:\n","        return nn.Sequential(\n","            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, bias=True),\n","            nn.LeakyReLU(0.1,inplace=True)\n","        )\n","\n","def predict_flow(in_planes):\n","    return nn.Conv2d(in_planes,2,kernel_size=3,stride=1,padding=1,bias=False)\n","\n","def deconv(in_planes, out_planes):\n","    return nn.Sequential(\n","        nn.ConvTranspose2d(in_planes, out_planes, kernel_size=4, stride=2, padding=1, bias=False),\n","        nn.LeakyReLU(0.1,inplace=True)\n","    )\n","\n","def crop_like(input, target):\n","    if input.size()[2:] == target.size()[2:]:\n","        return input\n","    else:\n","        return input[:, :, :target.size(2), :target.size(3)]"]},{"cell_type":"markdown","metadata":{},"source":["# Correlation function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install spatial-correlation-sampler\n","from spatial_correlation_sampler import spatial_correlation_sample\n","\n","def correlate(input1, input2):\n","    out_corr = spatial_correlation_sample(input1, input2, kernel_size=1, patch_size=21, stride=1, padding=0, dilation_patch=2)\n","    # collate dimensions 1 and 2 in order to be treated as a\n","    # regular 4D tensor\n","    b, ph, pw, h, w = out_corr.size()\n","    out_corr = out_corr.view(b, ph * pw, h, w)/input1.size(1)\n","    return F.leaky_relu_(out_corr, 0.1)"]},{"cell_type":"markdown","metadata":{"id":"-VrZQVb66gwO"},"source":["# **Network architecture of FlowNetC**"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1637023683826,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"_ojq1_Eqva3p"},"outputs":[],"source":["class FlowNetC(nn.Module):\n","    expansion = 1\n","    def __init__(self,batchNorm=True):\n","        super(FlowNetC,self).__init__()\n","        self.batchNorm = batchNorm\n","        self.conv1      = conv(self.batchNorm,   3,   64, kernel_size=7, stride=2)\n","        self.conv2      = conv(self.batchNorm,  64,  128, kernel_size=5, stride=2)\n","        self.conv3      = conv(self.batchNorm, 128,  256, kernel_size=5, stride=2)\n","        self.conv_redir = conv(self.batchNorm, 256,   32, kernel_size=1, stride=1)\n","\n","        self.conv3_1 = conv(self.batchNorm, 473,  256)\n","        self.conv4   = conv(self.batchNorm, 256,  512, stride=2)\n","        self.conv4_1 = conv(self.batchNorm, 512,  512)\n","        self.conv5   = conv(self.batchNorm, 512,  512, stride=2)\n","        self.conv5_1 = conv(self.batchNorm, 512,  512)\n","        self.conv6   = conv(self.batchNorm, 512, 1024, stride=2)\n","        self.conv6_1 = conv(self.batchNorm,1024, 1024)\n","\n","        self.deconv5 = deconv(1024,512)\n","        self.deconv4 = deconv(1026,256)\n","        self.deconv3 = deconv(770,128)\n","        self.deconv2 = deconv(386,64)\n","\n","        self.predict_flow6 = predict_flow(1024)\n","        self.predict_flow5 = predict_flow(1026)\n","        self.predict_flow4 = predict_flow(770)\n","        self.predict_flow3 = predict_flow(386)\n","        self.predict_flow2 = predict_flow(194)\n","\n","        self.upsampled_flow6_to_5 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n","        self.upsampled_flow5_to_4 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n","        self.upsampled_flow4_to_3 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n","        self.upsampled_flow3_to_2 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","                kaiming_normal_(m.weight, 0.1)\n","                if m.bias is not None:\n","                    constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                constant_(m.weight, 1)\n","                constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        x1 = x[:,:3]\n","        x2 = x[:,3:]\n","\n","        out_conv1a = self.conv1(x1)\n","        out_conv2a = self.conv2(out_conv1a)\n","        out_conv3a = self.conv3(out_conv2a)\n","\n","        out_conv1b = self.conv1(x2)\n","        out_conv2b = self.conv2(out_conv1b)\n","        out_conv3b = self.conv3(out_conv2b)\n","\n","        out_conv_redir = self.conv_redir(out_conv3a)\n","        out_correlation = correlate(out_conv3a,out_conv3b)\n","\n","        in_conv3_1 = torch.cat([out_conv_redir, out_correlation], dim=1)\n","\n","        out_conv3 = self.conv3_1(in_conv3_1)\n","        out_conv4 = self.conv4_1(self.conv4(out_conv3))\n","        out_conv5 = self.conv5_1(self.conv5(out_conv4))\n","        out_conv6 = self.conv6_1(self.conv6(out_conv5))\n","\n","        flow6       = self.predict_flow6(out_conv6)\n","        flow6_up    = crop_like(self.upsampled_flow6_to_5(flow6), out_conv5)\n","        out_deconv5 = crop_like(self.deconv5(out_conv6), out_conv5)\n","\n","        concat5 = torch.cat((out_conv5,out_deconv5,flow6_up),1)\n","        flow5       = self.predict_flow5(concat5)\n","        flow5_up    = crop_like(self.upsampled_flow5_to_4(flow5), out_conv4)\n","        out_deconv4 = crop_like(self.deconv4(concat5), out_conv4)\n","\n","        concat4 = torch.cat((out_conv4,out_deconv4,flow5_up),1)\n","        flow4       = self.predict_flow4(concat4)\n","        flow4_up    = crop_like(self.upsampled_flow4_to_3(flow4), out_conv3)\n","        out_deconv3 = crop_like(self.deconv3(concat4), out_conv3)\n","\n","        concat3 = torch.cat((out_conv3,out_deconv3,flow4_up),1)\n","        flow3       = self.predict_flow3(concat3)\n","        flow3_up    = crop_like(self.upsampled_flow3_to_2(flow3), out_conv2a)\n","        out_deconv2 = crop_like(self.deconv2(concat3), out_conv2a)\n","\n","        concat2 = torch.cat((out_conv2a,out_deconv2,flow3_up),1)\n","        flow2 = self.predict_flow2(concat2)\n","\n","        if self.training:\n","            return flow2,flow3,flow4,flow5,flow6\n","        else:\n","            return flow2\n","\n","    def weight_parameters(self):\n","        return [param for name, param in self.named_parameters() if 'weight' in name]\n","\n","    def bias_parameters(self):\n","        return [param for name, param in self.named_parameters() if 'bias' in name]\n","\n","def flownetc(data=None):\n","    \"\"\"FlowNetS model architecture from the\n","    \"Learning Optical Flow with Convolutional Networks\" paper (https://arxiv.org/abs/1504.06852)\n","    Args:\n","        data : pretrained weights of the network. will create a new one if not set\n","    \"\"\"\n","    model = FlowNetC(batchNorm=False)\n","    if data is not None:\n","        model.load_state_dict(data['state_dict'])\n","    return model\n","\n","\n","def flownetc_bn(data=None):\n","    \"\"\"FlowNetS model architecture from the\n","    \"Learning Optical Flow with Convolutional Networks\" paper (https://arxiv.org/abs/1504.06852)\n","    Args:\n","        data : pretrained weights of the network. will create a new one if not set\n","    \"\"\"\n","    model = FlowNetC(batchNorm=True)\n","    if data is not None:\n","        model.load_state_dict(data['state_dict'])\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"6KXXUjZI6kiC"},"source":["#**Import custom images**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27202,"status":"ok","timestamp":1637023712515,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"2AQ9Ke0NMm58","outputId":"dd70a1b4-3a87-4f20-e1a0-286f54ef3d14"},"outputs":[],"source":["# any number 0~200\n","image_num = 46 \n","image_left_prefix = 'image_2'\n","\n","img_dir = os.path.join(kitti_flow_datapath, image_left_prefix)\n","\n","img_t0_name = os.path.join(img_dir, str(image_num).zfill(6) + '_10.png')\n","img_t1_name = os.path.join(img_dir, str(image_num).zfill(6) + '_11.png')\n","\n","img_t0 = imread(img_t0_name)\n","img_t1 = imread(img_t1_name)\n","\n","\n","input_transform = transforms.Compose([\n","    ArrayToTensor(),\n","    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n","    transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n","])\n","\n","\n","img1 = input_transform(img_t0)\n","img2 = input_transform(img_t1)\n","input_var = torch.cat([img1, img2]).unsqueeze(0)\n","\n","# create model\n","flownet_ckpt_name = 'flownetc_EPE1.766.tar'\n","pretrained_model = os.path.join(base_path, 'Pretrained', flownet_ckpt_name)\n","checkpoint = torch.load(pretrained_model)\n","print(\"=> using pre-trained model '{}'\".format(checkpoint['arch']))\n","\n","model = flownetc(checkpoint).to(device)\n","model.eval()\n","cudnn.benchmark = True\n","\n","bidirectional = True\n","if bidirectional:\n","    # feed inverted pair along with normal pair\n","    inverted_input_var = torch.cat([img2, img1]).unsqueeze(0)\n","    input_var = torch.cat([input_var, inverted_input_var])\n","\n","input_var = input_var.to(device)\n","# compute output\n","flow_output = model(input_var)"]},{"cell_type":"markdown","metadata":{"id":"1MYI4Y8I6sWW"},"source":["#**Print model architecture summary**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1637023852396,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"0iw_gxcSjILc","outputId":"ca1fb683-5a2a-4d21-c198-101e04ad1279"},"outputs":[],"source":["print(model)"]},{"cell_type":"markdown","metadata":{"id":"XUuhTSU_6wzN"},"source":["#**Optical flow visualization**"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":303,"status":"ok","timestamp":1637023882001,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"yZ7Z6TuFE8Fq"},"outputs":[],"source":["def flow2rgb(flow_map, max_value):\n","    flow_map_np = flow_map.detach().cpu().numpy()\n","    _, h, w = flow_map_np.shape\n","    flow_map_np[:,(flow_map_np[0] == 0) & (flow_map_np[1] == 0)] = float('nan')\n","    rgb_map = np.ones((3,h,w)).astype(np.float32)\n","    if max_value is not None:\n","        normalized_flow_map = flow_map_np / max_value\n","    else:\n","        normalized_flow_map = flow_map_np / (np.abs(flow_map_np).max())\n","    rgb_map[0] += normalized_flow_map[0]\n","    rgb_map[1] -= 0.5*(normalized_flow_map[0] + normalized_flow_map[1])\n","    rgb_map[2] += normalized_flow_map[1]\n","    return rgb_map.clip(0,1)"]},{"cell_type":"markdown","metadata":{"id":"rJlH8rCu60DU"},"source":["#**Optical flow estimation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":609},"executionInfo":{"elapsed":3034,"status":"ok","timestamp":1637023919952,"user":{"displayName":"Yujeong Chae","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10131130949842181370"},"user_tz":-540},"id":"FiuQyjGSMgvI","outputId":"5f6f14a1-5f92-4182-dc49-57788c12b646"},"outputs":[],"source":["rgb_flow = flow2rgb(20 * flow_output[0], max_value=20)\n","rgb_inv_flow = flow2rgb(20 * flow_output[1], max_value=20)\n","rgb_flow_viz = (rgb_flow * 255).astype(np.uint8).transpose(1,2,0)\n","rgb_flow_inv_viz = (rgb_inv_flow * 255).astype(np.uint8).transpose(1,2,0)\n","\n","\n","plt.figure()\n","plt.title('first image')\n","plt.imshow(img_t0)\n","\n","plt.figure()\n","plt.title('second image')\n","plt.imshow(img_t1)\n","\n","plt.figure()\n","plt.title('flow result')\n","plt.imshow(rgb_flow_viz)\n","\n","plt.figure()\n","plt.title('inv flow result')\n","plt.imshow(rgb_flow_inv_viz)\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOatqyR1usiST5kZmqKAfSO","name":"Kitti_TA_Session_flownet","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
